{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What's Cooking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Join the What’s Cooking competition on Kaggle. Download the training and test data (in .json). The competition page describes how these files are formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_json('cooking/train.json')\n",
    "test = pd.read_json('cooking/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Tell us about the data. How many samples (dishes) are there in the training set? How many categories (types of cuisine)? Use a list to keep all the unique ingredients appearing in the training set. How many unique ingredients are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 39774 samples in the the training set.\n"
     ]
    }
   ],
   "source": [
    "num_of_s = len(train)\n",
    "print('There are', num_of_s, 'samples in the the training set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 types of cuisines in the the training set.\n"
     ]
    }
   ],
   "source": [
    "cuisine = train['cuisine'].unique()\n",
    "num_of_c = len(cuisine)\n",
    "print('There are', num_of_c, 'types of cuisines in the the training set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6714 unique ingredients in the the training set.\n"
     ]
    }
   ],
   "source": [
    "import itertools \n",
    "ingd = set(list(itertools.chain(*train['ingredients'])))\n",
    "ingd = np.array(list(ingd))\n",
    "num_of_i = len(ingd)\n",
    "print('There are', num_of_i, 'unique ingredients in the the training set.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Represent each dish by a binary ingredient feature vector. Suppose there are d different in- gredients in total from the training set, represent each dish by a 1×d binary ingredient vector x, where xi = 1 if the dish contains ingredient i and xi = 0 otherwise. For example, suppose all the ingredients we have in the training set are { beef, chicken, egg, lettuce, tomato, rice } and the dish is made by ingredients { chicken, lettuce, tomato, rice }, then the dish could be represented by a 6 × 1 binary vector [0, 1, 0, 1, 1, 1] as its feature or attribute. Use n × d feature matrix to represent all the dishes in training set and test set, where n is the number of dishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flan</th>\n",
       "      <th>golden raisins</th>\n",
       "      <th>grape leaves</th>\n",
       "      <th>chocolate fudge ice cream</th>\n",
       "      <th>strawberries</th>\n",
       "      <th>apple juice</th>\n",
       "      <th>mature cheddar</th>\n",
       "      <th>pork loin</th>\n",
       "      <th>vanilla flavoring</th>\n",
       "      <th>brioche bread</th>\n",
       "      <th>...</th>\n",
       "      <th>katakuriko</th>\n",
       "      <th>knorr tomato bouillon with chicken flavor cube</th>\n",
       "      <th>chocolate candy bars</th>\n",
       "      <th>low sodium tomato</th>\n",
       "      <th>chocolate milk mix</th>\n",
       "      <th>vanilla instant pudding</th>\n",
       "      <th>tatsoi</th>\n",
       "      <th>popcorn chicken</th>\n",
       "      <th>turkey sausage</th>\n",
       "      <th>perilla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 6714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [flan, golden raisins, grape leaves, chocolate fudge ice cream, strawberries, apple juice, mature cheddar, pork loin, vanilla flavoring, brioche bread, Stonefire Italian Artisan Pizza Crust, Johnsonville Mild Italian Sausage Links, green gram, 2 1/2 to 3 lb. chicken, cut into serving pieces, instant oats, nut oil, refrigerated bread dough, part-skim ricotta cheese, pie crust mix, haloumi, macaroni, somen, sweet cream butter, ground red pepper, reduced sodium chicken bouillon granules, country crock calcium plus vitamin d, guanciale, jerk rub seasoning, double-acting baking powder, ragu old world style pasta sauc, blanco chees queso, creamy peanut butter, whole wheat rigatoni, cream of chicken soup, sichuanese chili paste, hot bean paste, cracker meal, umeboshi plum vinegar, loose leaf black tea, dill seed, yaki-nori, white radish, tongue, Oscar Mayer Deli Fresh Smoked Ham, kimchi juice, Challenge Butter, salt water, asian rice noodles, crab, rioja, brine-cured olives, doenzang, Poire Williams, hot pepperoni, mini chocolate chips, portabello mushroom, poppy seed dressing, mixed peel, gemelli, lamb rib roast, black vinegar, boneless chuck roast, eye steaks, dried currants, dried navy beans, clear honey, whole wheat cereal, chocolate instant pudding, red velvet cake mix, Elmlea single, red grapefruit juice, Herdez Salsa Verde, cheese dip, praline, fish steaks, chunky style pasta sauce, black turtle beans, butter oil, asiago, Gochujang base, shrimp powder, frozen stir fry vegetable blend, blackening seasoning, diced tomatoes with garlic and onion, Lipton Sparkling Diet Green Tea with Strawberry Kiwi, frisee, black cod, mora chiles, minced meat, chicken-apple sausage, pickled garlic, cooked rice, cachaca, reduced-sodium tamari sauce, candy, crepes, iced tea, Progresso™ Chicken Broth, breast, coffee granules, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 6714 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns = ingd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feature(s):\n",
    "    x = np.array([0]*6714)\n",
    "    for i in s:\n",
    "        a = (ingd == i)*1\n",
    "        x = np.array([x,a]).sum(axis = 0)\n",
    "    return x \n",
    "s = train['ingredients']\n",
    "m = list(map(feature, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix = pd.DataFrame(np.array(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6714)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Using Naïve Bayes Classifier to perform 3 fold cross-validation on the training set and report your average classification accuracy. Try both Gaussian distribution prior assumption and Bernoulli distribution prior assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(matrix, train['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1 = matrix\n",
    "train1['cuisine'] = train['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.37901644290239855, 0.38293860310755767, 0.37765877206215115]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3)\n",
    "gnb_accuracy = []\n",
    "for train_id, test_id in kf.split(train1):\n",
    "    train = train1.iloc[train_id]\n",
    "    test = train1.iloc[test_id]\n",
    "    train_y = train['cuisine']\n",
    "    train_x = train.drop('cuisine', axis = 1)\n",
    "    test_y = test['cuisine']\n",
    "    test_x = test.drop('cuisine', axis = 1)\n",
    "    \n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_x, train_y)\n",
    "    prediction = gnb.predict(test_x)\n",
    "    ac = accuracy_score(test_y, prediction)\n",
    "    gnb_accuracy.append(ac)\n",
    "gnb_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.68419067732689698, 0.67951425554382261, 0.68690601900739179]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits = 3)\n",
    "bn_accuracy = []\n",
    "for train_id, test_id in kf.split(train1):\n",
    "    train = train1.iloc[train_id]\n",
    "    test = train1.iloc[test_id]\n",
    "    train_y = train['cuisine']\n",
    "    train_x = train.drop('cuisine', axis = 1)\n",
    "    test_y = test['cuisine']\n",
    "    test_x = test.drop('cuisine', axis = 1)\n",
    "    \n",
    "    bn = BernoulliNB()\n",
    "    bn.fit(train_x, train_y)\n",
    "    prediction = bn.predict(test_x)\n",
    "    ac = accuracy_score(test_y, prediction)\n",
    "    bn_accuracy.append(ac)\n",
    "bn_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) For Gaussian prior and Bernoulli prior, which performs better in terms of cross-validation accuracy? Why? Please give specific arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Bernoulli Naive Bayes Classifier perform better. <br>\n",
    "Reasons: \n",
    "1. Gaussian NB assumes the data is normally distributed but the data we have is binary so the bernoulli will have better fit. <br>\n",
    "2. Gaussian NB assumes the data is continous with order but our data is discontinous and doesn't have order. So, bernoulli NB should perform better. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Using Logistic Regression Model to perform 3 fold cross-validation on the training set and report your average classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.77590888520138779, 0.77213757731181176, 0.7786242268818826]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "kf = KFold(n_splits = 3)\n",
    "lr_accuracy = []\n",
    "for train_id, test_id in kf.split(train1):\n",
    "    train = train1.iloc[train_id]\n",
    "    test = train1.iloc[test_id]\n",
    "    train_y = train['cuisine']\n",
    "    train_x = train.drop('cuisine', axis = 1)\n",
    "    test_y = test['cuisine']\n",
    "    test_x = test.drop('cuisine', axis = 1)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(train_x, train_y)\n",
    "    prediction = lr.predict(test_x)\n",
    "    ac = accuracy_score(test_y, prediction)\n",
    "    lr_accuracy.append(ac)\n",
    "lr_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Train your best-performed classifier with all of the training data, and generate test labels on test set. Submit your results to Kaggle and report the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('cooking/train.json')\n",
    "test = pd.read_json('cooking/test.json')\n",
    "train_x = matrix.drop('cuisine', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_m = list(map(feature, test['ingredients']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_x = pd.DataFrame(np.array(test_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_x, train['cuisine'])\n",
    "prediction = lr.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'id': test['id'], 'cuisine': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.to_csv('cooking_prediction.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy: 0.783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
