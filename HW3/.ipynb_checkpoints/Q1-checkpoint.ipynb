{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Download Sentiment Labelled Sentences Data Set. There are three data files under the root folder. yelp_labelled.txt, amazon_cells_labelled.txt and imdb_labelled.txt. Parse each file with the specifications in readme.txt. Are the labels balanced? If not, what’s the ratio between the two labels? Explain how you process these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read yelp\n",
    "yelp = []\n",
    "for line in open('sentiment labelled sentences/yelp_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    review = line[:-2]\n",
    "    label = line[-1]\n",
    "    yelp.append([review, int(label)])\n",
    "yelp = pd.DataFrame(yelp, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read amazon\n",
    "amazon = []\n",
    "for line in open('sentiment labelled sentences/amazon_cells_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    review = line[:-2]\n",
    "    label = line[-1]\n",
    "    amazon.append([review, int(label)])\n",
    "amazon = pd.DataFrame(amazon, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## read imdb\n",
    "imdb = []\n",
    "for line in open('sentiment labelled sentences/imdb_labelled.txt'):\n",
    "    line = line.strip('\\n')\n",
    "    review = line[:-2]\n",
    "    label = line[-1]\n",
    "    imdb.append([review, int(label)])\n",
    "imdb = pd.DataFrame(imdb, columns = ['Review', 'Sent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check label ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio between positive and negative reviews in yelp are  1.0\n"
     ]
    }
   ],
   "source": [
    "r_y = (yelp.Sent == 1).sum()/ (len(yelp) - (yelp.Sent == 1).sum())\n",
    "print('The ratio between positive and negative reviews in yelp are ', r_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio between positive and negative reviews in amazon are  1.0\n"
     ]
    }
   ],
   "source": [
    "r_a = (amazon.Sent == 1).sum()/ (len(amazon) - (amazon.Sent == 1).sum())\n",
    "print('The ratio between positive and negative reviews in amazon are ', r_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ratio between positive and negative reviews in imdb are  1.0\n"
     ]
    }
   ],
   "source": [
    "r_i = (imdb.Sent == 1).sum()/ (len(imdb) - (imdb.Sent == 1).sum())\n",
    "print('The ratio between positive and negative reviews in imdb are ', r_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the labels in each file are balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Pick your preprocessing strategy. Since these sentences are online reviews, they may con- tain significant amounts of noise and garbage. You may or may not want to do one or all of the following. Explain the reasons for each of your decision (why or why not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sent\n",
       "0                           Wow... Loved this place.     1\n",
       "1                                 Crust is not good.     0\n",
       "2          Not tasty and the texture was just nasty.     0\n",
       "3  Stopped by during the late May bank holiday of...     1\n",
       "4  The selection on the menu was great and so wer...     1\n",
       "5     Now I am getting angry and I want my damn pho.     0\n",
       "6              Honeslty it didn't taste THAT fresh.)     0\n",
       "7  The potatoes were like rubber and you could te...     0\n",
       "8                          The fries were great too.     1\n",
       "9                                     A great touch.     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk import *\n",
    "from nltk.stem.snowball import SnowballStemmer as SBS\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Lemmatization \n",
    "def lem(s):\n",
    "    ps = SBS('english')\n",
    "    ls_stem = [ps.stem(word) for word in s.split()]\n",
    "    return ' '.join(ls_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove the certain list of words in the string\n",
    "def rmv(s, ls):\n",
    "    return ' '.join(filter(lambda s: s not in ls, s.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow love place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tasti textur nasti</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stop late may bank holiday rick steve recommen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>select menu great price</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Sent\n",
       "0                                     wow love place     1\n",
       "1                                         crust good     0\n",
       "2                                 tasti textur nasti     0\n",
       "3  stop late may bank holiday rick steve recommen...     1\n",
       "4                            select menu great price     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(df):\n",
    "    data = df\n",
    "    \n",
    "    ## remove punctuation\n",
    "    punc = '[' + string.punctuation + ']'\n",
    "    data.Review = data.Review.apply(lambda x: re.sub(punc, '', x))\n",
    "    \n",
    "    ## lowercase\n",
    "    data.Review = data.Review.apply(lambda x: x.lower())\n",
    "    \n",
    "    ## remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    data.Review = data.Review.apply(lambda x: rmv(x, sw))\n",
    "    \n",
    "    ## Lemmatization \n",
    "    data.Review = data.Review.apply(lambda x: lem(x))\n",
    "    \n",
    "    return data\n",
    "yelp = preprocess(yelp)\n",
    "amazon = preprocess(amazon)\n",
    "imdb = preprocess(imdb)\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reason: <br>\n",
    "* Lowercase: Since the uppercase words and lowercase words have the exactly same meaning in a sentence.\n",
    "* Lemmatization: The words such as run, running, ran, have similar meaning. It is easier to train a model if all words are lemmatized. \n",
    "* Strip punctuation: punctuations have very small influence on the sentiment of a sentence. \n",
    "* Strip stop words: Getting rid of stops words can help the model to better understand important words such as adj, nouns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Split training and testing set. In this assignment, for each file, please use the first 400 in- stances for each label as the training set and the remaining 100 instances as testing set. In total, there are 2400 reviews for training and 600 reviews for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mysplit(df):\n",
    "    df_1 = df[df.Sent == 1]\n",
    "    df_0 = df[df.Sent == 0]\n",
    "    train1 = df_1[:400]\n",
    "    test1 = df_1[400:]\n",
    "    train0 = df_0[:400]\n",
    "    test0 = df_0[400:]\n",
    "    return train1, test1, train0, test0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_train1, a_test1, a_train0, a_test0 = mysplit(amazon)\n",
    "y_train1, y_test1, y_train0, y_test0 = mysplit(yelp)\n",
    "i_train1, i_test1, i_train0, i_test0 = mysplit(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trains = [a_train1, a_train0, y_train1, y_train0, i_train1, i_train0]\n",
    "tests = [a_test1, a_test0, y_test1, y_test0, i_test1, i_test1]\n",
    "train = pd.concat(trains)\n",
    "test = pd.concat(tests)\n",
    "\n",
    "train.reset_index(inplace = True)\n",
    "train.drop('index',axis = 1, inplace = True)\n",
    "test.reset_index(inplace = True)\n",
    "test.drop('index',axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2400, 2), (600, 2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Bag of Words model. Extract features and then represent each review using bag of words model, i.e., every word in the review becomes its own element in a feature vector. In order to do this, first, make one pass through all the reviews in the training set (Explain why we can’t use testing set at this point) and build a dictionary of unique words. Then, make another pass through the review in both the training set and testing set and count up the occurrences of each word in your dictionary. The ith element of a review’s feature vector is the number of occurrences of the i th dictionary word in the review. Implement the bag of words model and report feature vectors of any two reviews in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  3629  unique words in the training data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "## dictionary\n",
    "dic = np.array(list(set(' '.join(train.Review).split())))\n",
    "print('There are ', len(dic), ' unique words in the training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The reason we can't use test data for creating dictionary is that we need use training data to train a model and training data may not have all the words that test data has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag(s):\n",
    "    a = s.split()\n",
    "    v = np.sum([dic == w for w in a],axis=0)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## transfer reviews\n",
    "train['vector'] = train.Review.apply(bag)\n",
    "test['vector'] = test.Review.apply(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impress go origin batteri extend batteri\n",
      "[0 0 0 ..., 0 0 0]\n",
      "bought use kindl fire absolut love\n",
      "[0 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "## two reviews and feature vectors\n",
    "for z in [5,10]:\n",
    "    print(train.Review[z])\n",
    "    print(train.vector[z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(e) Pick your post processing strategy. Since the vast majority of English words will not appear in most of the reviews, most of the feature vector elements will be 0. This suggests that we need a postprocessing or normalization strategy that combats the huge variance of the elements in the feature vector. You may want to use one of the following strategies. Whatever choices you make, explain why you made the decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using log-normalization since it can reduce the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['log vector'] = train.vector.apply(lambda x: np.log(x+1))\n",
    "test['log vector'] = test.vector.apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Sentiment prediction. Train a logistic regression model (you can use existing packages here) on the training set and test on the testing set. Report the classification accuracy and confu- sion matrix. Inspecting the weight vector of the logistic regression, what are the words that play the most important roles in deciding the sentiment of the reviews? Repeat this with a Naive Bayes classifier and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as logit\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.vstack(train['log vector'])\n",
    "y_train = train.Sent\n",
    "x_test = np.vstack(test['log vector'])\n",
    "y_test = test.Sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 0.5, 1, 5, 10, 50]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {'C': [0.1, 0.5, 1, 5, 10, 50]\n",
    "        }\n",
    "clf = GridSearchCV(logit(penalty = 'l2'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.81\n"
     ]
    }
   ],
   "source": [
    "logit_prediction = clf.predict(x_test)\n",
    "print('Accuracy: ', clf.best_estimator_.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[176,  24],\n",
       "       [ 90, 310]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test, logit_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = logit(penalty = 'l2', C = 5)\n",
    "l.fit(x_train, y_train)\n",
    "ind = abs(l.coef_)\n",
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beauti', 'fantast', 'worst', 'amaz', 'excel', 'bad', 'delici',\n",
       "       'poor', 'love', 'great'], \n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.785\n"
     ]
    }
   ],
   "source": [
    "BNB_prediction = BNB.predict(x_test)\n",
    "print('Accuracy: ', BNB.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[168,  32],\n",
       "       [ 97, 303]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test, BNB_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(g) N-gram model. Similar to the bag of words model, but now you build up a dictionary of n- grams, which are contiguous sequences of words. For example, “Alice fell down the rabbit hole” would then map to the 2-grams sequence: [\"Alice fell\", \"fell down\", \"down the\", \"the rabbit\", \"rabbit hole\"], and all five of those symbols would be members of the n-gram dictio- nary. Try n = 2, repeat (d)-(g) and report your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_gram(s):\n",
    "    s_s = s.split()\n",
    "    return [s_s[i] + ' ' + s_s[i+1] for i in range(len(s_s)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['two_gram'] = train.Review.apply(two_gram)\n",
    "test['two_gram'] = test.Review.apply(two_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "dic_w = np.array(list(set(itertools.chain(*train.two_gram))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## two-gram feature\n",
    "def two_g(s):\n",
    "    if s == []:\n",
    "        return np.array([0]*len(dic_w))\n",
    "    else:\n",
    "        v = np.sum([dic_w == w for w in s],axis=0)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['vector_2g'] = train.two_gram.apply(two_g)\n",
    "test['vector_2g'] = test.two_gram.apply(two_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['vector_2g_log'] = train.vector_2g.apply(lambda x: np.log(x+1))\n",
    "test['vector_2g_log'] = test.vector_2g.apply(lambda x: np.log(x+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_l = np.vstack(train['vector_2g_log'])\n",
    "y_train_l = train.Sent\n",
    "x_test_l = np.vstack(test['vector_2g_log'])\n",
    "y_test_l = test.Sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.1, 0.5, 1, 2, 5, 10, 50]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {'C': [0.1, 0.5, 1, 2, 5, 10, 50]}\n",
    "clf = GridSearchCV(logit(penalty='l2'), paras, cv = 5, n_jobs = -1)\n",
    "clf.fit(x_train_l, y_train_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.55\n"
     ]
    }
   ],
   "source": [
    "logit_prediction = clf.predict(x_test_l)\n",
    "print('Accuracy: ', clf.best_estimator_.score(x_test_l, y_test_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[176,  24],\n",
       "       [246, 154]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test_l, logit_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.548333333333\n",
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[179,  21],\n",
       "       [250, 150]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train_l, y_train_l)\n",
    "\n",
    "BNB_prediction = BNB.predict(x_test_l)\n",
    "print('Accuracy: ', BNB.score(x_test_l, y_test_l))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "confusion_matrix(y_test_l, BNB_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(h) PCA for bag of words model. The features in the bag of words model have large redundancy. Implement PCA to reduce the dimension of features calculated in (e) to 10, 50 and 100 re- spectively. Using these lower-dimensional feature vectors and repeat (f), (g). Report corre- sponding clustering and classification results. (Note: You should implement PCA yourself, but you can use numpy.svd or some other SVD package. Feel free to double-check your PCA implementation against an existing one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### My PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 3629)\n"
     ]
    }
   ],
   "source": [
    "## feature matrix\n",
    "fm = np.vstack(train['log vector'])\n",
    "print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_m(df):\n",
    "    mean_vector = np.mean(df,axis=1).reshape(-1,1)\n",
    "\n",
    "    ## substract mean\n",
    "    return df - mean_vector\n",
    "fm_sub_m = sub_m(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## covariance matrix\n",
    "def get_cm(c):                  ## input matrix (samples x observations)\n",
    "    m = c.T\n",
    "\n",
    "    num_f, num_o = m.shape\n",
    "\n",
    "    ## find mean\n",
    "    mean_vector = np.mean(m,axis=1).reshape(-1,1)\n",
    "    \n",
    "    ## substract mean\n",
    "    fm_sub_m = m - mean_vector\n",
    "    \n",
    "    ## find covariance \n",
    "    covariance_m = fm_sub_m.dot(fm_sub_m.T)/(num_o - 1)\n",
    "    \n",
    "    return covariance_m\n",
    "\n",
    "cm = get_cm(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## diagnonalization\n",
    "\n",
    "def diagonalize(m):\n",
    "    \n",
    "    evalues, evectors = np.linalg.eigh(m)\n",
    "    idx = evalues.argsort()[::-1]\n",
    "    evalues = np.diag(evalues[idx])\n",
    "    evectors = evectors[:,idx]\n",
    "    \n",
    "    return evalues, evectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "E, P = diagonalize(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3629, 3629)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##principal component\n",
    "\n",
    "## dimension reduction\n",
    "x_train10 = fm_sub_m.dot(P[:,:10])\n",
    "x_train50 = fm_sub_m.dot(P[:,:50])\n",
    "x_train100 = fm_sub_m.dot(P[:,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##dim reduction for test data\n",
    "fm_test = np.vstack(test['log vector'])\n",
    "test_mean = np.mean(fm_test,axis=1).reshape(-1,1)\n",
    "    \n",
    "## substract mean\n",
    "fm_test_sub_m = fm_test - test_mean\n",
    "\n",
    "x_test10 = fm_test_sub_m.dot(P[:,:10])\n",
    "x_test50 = fm_test_sub_m.dot(P[:,:50])\n",
    "x_test100 = fm_test_sub_m.dot(P[:,:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.548333333333\n",
      "Confusion Matrix: \n",
      " [[174  26]\n",
      " [245 155]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.675\n",
      "Confusion Matrix: \n",
      " [[170  30]\n",
      " [165 235]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.696666666667\n",
      "Confusion Matrix: \n",
      " [[158  42]\n",
      " [140 260]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50,100]:\n",
    "    \n",
    "    exec('x_train_pc = x_train' + str(i))\n",
    "    exec('x_test_pc = x_test' + str(i))\n",
    "\n",
    "    paras = {'C': [0.1, 0.5, 1, 5, 10, 50]\n",
    "            }\n",
    "    clf = GridSearchCV(logit(penalty = 'l2'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "    clf.fit(x_train_pc, y_train)\n",
    "\n",
    "    logit_prediction = clf.predict(x_test_pc)\n",
    "\n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', clf.best_estimator_.score(x_test_pc, y_test_l))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test_l, logit_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.585\n",
      "Confusion Matrix: \n",
      " [[120  80]\n",
      " [169 231]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.606666666667\n",
      "Confusion Matrix: \n",
      " [[129  71]\n",
      " [165 235]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.638333333333\n",
      "Confusion Matrix: \n",
      " [[129  71]\n",
      " [146 254]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50, 100]:\n",
    "    \n",
    "    exec('x_train_pc = x_train' + str(i))\n",
    "    exec('x_test_pc = x_test' + str(i))\n",
    "    \n",
    "    BNB = BernoulliNB()\n",
    "    BNB.fit(x_train_pc, y_train)\n",
    "    BNB_prediction = BNB.predict(x_test_pc)\n",
    "    \n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', BNB.score(x_test_pc, y_test))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, BNB_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PCA for two grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## feature matrix\n",
    "fm2 = np.vstack(train.vector_2g_log)\n",
    "\n",
    "fm2 = sub_m(fm2)\n",
    "\n",
    "## covariance matrix\n",
    "def get_cm(c):                  ## input matrix (samples x observations)\n",
    "    m = c.T\n",
    "\n",
    "    num_f, num_o = m.shape\n",
    "\n",
    "    ## find mean\n",
    "    mean_vector = np.mean(m,axis=1).reshape(-1,1)\n",
    "    \n",
    "    ## substract mean\n",
    "    fm_sub_m = m - mean_vector\n",
    "    \n",
    "    ## find covariance \n",
    "    covariance_m = fm_sub_m.dot(fm_sub_m.T)/(num_o - 1)\n",
    "    \n",
    "    return covariance_m\n",
    "\n",
    "cm2 = get_cm(fm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## diagnonalization\n",
    "def diagonalize(m):\n",
    "    \n",
    "    evalues, evectors = np.linalg.eigh(m)\n",
    "    idx = evalues.argsort()[::-1]\n",
    "    evalues = np.diag(evalues[idx])\n",
    "    evectors = evectors[:,idx]\n",
    "    \n",
    "    return evalues, evectors\n",
    "\n",
    "E2, P2 = diagonalize(cm2)\n",
    "\n",
    "##principal component\n",
    "\n",
    "## dimension reduction\n",
    "x_2_train10 = fm2.dot(P2[:,:10])\n",
    "x_2_train50 = fm2.dot(P2[:,:50])\n",
    "x_2_train100 = fm2.dot(P2[:,:100])\n",
    "\n",
    "\n",
    "##dim reduction for test data\n",
    "fm2_test = np.vstack(test.vector_2g_log)\n",
    "fm2_test = sub_m(fm2_test)\n",
    "\n",
    "x_2_test10 = fm2_test.dot(P2[:,:10])\n",
    "x_2_test50 = fm2_test.dot(P2[:,:50])\n",
    "x_2_test100 = fm2_test.dot(P2[:,:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.341666666667\n",
      "Confusion Matrix: \n",
      " [[198   2]\n",
      " [393   7]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.573333333333\n",
      "Confusion Matrix: \n",
      " [[ 58 142]\n",
      " [114 286]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.595\n",
      "Confusion Matrix: \n",
      " [[ 52 148]\n",
      " [ 95 305]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50,100]:\n",
    "    \n",
    "    exec('x_2_train_pc = x_2_train' + str(i))\n",
    "    exec('x_2_test_pc = x_2_test' + str(i))\n",
    "\n",
    "    paras = {'C': [0.1, 0.5, 1, 5, 10, 50]\n",
    "            }\n",
    "    clf = GridSearchCV(logit(penalty = 'l2'), paras, cv = 5, n_jobs = -1, scoring = 'accuracy' )\n",
    "    clf.fit(x_2_train_pc, y_train)\n",
    "\n",
    "    logit_prediction = clf.predict(x_2_test_pc)\n",
    "\n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', clf.best_estimator_.score(x_2_test_pc, y_test_l))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, logit_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with PC 10:\n",
      "Accuracy:  0.371666666667\n",
      "Confusion Matrix: \n",
      " [[194   6]\n",
      " [371  29]]\n",
      "\n",
      "\n",
      "Performance with PC 50:\n",
      "Accuracy:  0.426666666667\n",
      "Confusion Matrix: \n",
      " [[172  28]\n",
      " [316  84]]\n",
      "\n",
      "\n",
      "Performance with PC 100:\n",
      "Accuracy:  0.436666666667\n",
      "Confusion Matrix: \n",
      " [[161  39]\n",
      " [299 101]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [10, 50, 100]:\n",
    "    \n",
    "    exec('x_2_train_pc = x_2_train' + str(i))\n",
    "    exec('x_2_test_pc = x_2_test' + str(i))\n",
    "    \n",
    "    BNB = BernoulliNB()\n",
    "    BNB.fit(x_2_train_pc, y_train)\n",
    "    BNB_prediction = BNB.predict(x_2_test_pc)\n",
    "    \n",
    "    print('Performance with PC ' + str(i) +':')\n",
    "    print('Accuracy: ', BNB.score(x_2_test_pc, y_test))\n",
    "    print('Confusion Matrix: \\n', confusion_matrix(y_test, BNB_prediction))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beauti', 'fantast', 'worst', 'amaz', 'excel', 'bad', 'delici',\n",
       "       'poor', 'love', 'great'], \n",
       "      dtype='<U32')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = logit(penalty = 'l2', C = 5)\n",
    "l.fit(x_train, y_train)\n",
    "ind = abs(l.coef_)\n",
    "z = dic[np.argsort(ind)]\n",
    "z[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['good price', 'realli good', 'easi use', 'food good',\n",
       "       'great product', 'one best', 'wast time', 'great phone',\n",
       "       'high recommend', 'work great'], \n",
       "      dtype='<U39')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = logit(penalty = 'l2', C = 5)\n",
    "l1.fit(x_train_l, y_train_l)\n",
    "ind = abs(l1.coef_)\n",
    "z1 = dic_w[np.argsort(ind)]\n",
    "z1[0][-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
